---
title: 漫谈卷积神经网络
date: 2017-11-24 18:00:00
tags:
	- Deep Learning
categories: 读论文
toc: true
---
现在各种复杂的神经网络模型当然不是突然出现在世界上的，一定有一个演进更新的过程。

<!--more-->
在图像分类领域，从古老的Lenet到如今的Resnet，这一路走来，人们在改进卷积神经网络模型方面发现了什么问题，做了哪些思考，又进行了什么改进。在这篇文章中，我会简单的介绍一下各个经典卷积神经网络模型都做出了什么改进，仅仅是主要思想，不涉及论文细节。

通俗意义上的卷积神经网络来自于1998，Yann LeCun、Yoshua等人搭建了一个多层神经网络模型，并且发现卷积操作对图像的特征提取有一个很好的表现，于是将卷积操作引入神经网络中，这也就是我们现在说的卷积神经网络。但是当时并没有引起很大的反响，因为卷积神经网络没有严谨的数学推理，并且在当时的无论是数据量和计算能力都无法撑起这个算法。这个现象我们通常叫做生不逢时。LeNet的结构如下图所示，简单清晰明了，来自1998年的卷积神经网络的基本组件包括卷积层、Pooling层和FC层我们现如今还在一直沿用。

时间来到2012年，在传说中的世界末日的这一年，我们迎来了真正意义上的卷积神经网络。斯坦福计算机视觉实验室，发起了一项比赛，也就是我们后来说的ImageNet，想要推得动计算机视觉的发展，在2012年来自Hinton及其学生Alex拿出了他们精心炼制的AlexNet卷积网络模型将图像分类的错误率降低了百分之十几，碾压式的拿到了这项比赛的冠军，而后就是深度学习的兴起，计算机视觉领域，深度学习模型埋掉了大部分经典理论。AlexNet如下图所示，不要问我为什么这个图被戒掉了一部分，原来论文中就是这么画的。

由于当时GPU容量和计算能力的限制，Alex把卷积得到的特征图分成两份，分别送入两个GPU中进行训练。分别进行卷积这件事儿并不仅仅这么简单，后来一部分工作就是建立在分别卷积上进行的，我们称之为**Group Convolution**。AlexNet有大量的参数,这是因为它的卷积核特别大，存在11x11、7x7等大型的卷积核，这会导致大量的存储成本和计算成本。所以在2014年来自牛津大学的计算机视觉组VGG提出了他们的想法。

VGG网络的核心思想就是取消掉大型的卷积核，用叠加的3x3的卷积核代替5x5和7x7的卷积核,这样一来，卷积核的大小减少了，模型大小也减少了，同时增加了网络深度，提高了模型的非线性程度，也就增加的模型的表达能力。通过实验提出了两种模型结构分别是VGG-16和VGG-19，这两个神经网络模型也是目前比较稳定的神经网络模型，应用非常广泛。 
